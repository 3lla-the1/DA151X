@book{krogh2009,
  author = {Krogh, Peter},
  title = {The DAM book: Digital asset management for photographers},
  edition = {2nd},
  publisher = {O'Reilly},
  address = {Sebastopol, California},
  year = {2009}
}

@article{teng2022,
  author = {Teng, Xiaoyan and Wu, Zhong and Yang, Feng},
  title = {Impact of the Digital Transformation of Small- and Medium-Sized Listed Companies on Performance: Based on a Cost-Benefit Analysis Framework},
  journal = {Journal of Mathematics},
  year = {2022},
  volume = {2022},
  pages = {1-15},
  doi = {10.1155/2022/1504499}
}

@techreport{tillvaxtverket2021,
  author = {Tillväxtverket},
  title = {Små och medelstora företags digitalisering - vad har betydelse?},
  institution = {Tillväxtverket},
  year = {2021},
  number = {0366},
  isbn = {978-91-89255-10-4},
  url = {https://tillvaxtverket.se/tillvaxtverket/publikationer/publikationer2021/smaochmedelstoraforetagsdigitalisering.1422.html},
  note = {Accessed: 2025-02-15}
}

@book{mccain2021,
  author = {McCain, Edward and Mara, Neil and Van Malssen, Kara and Carner, Dorothy and Reilly, Bernard and Willette, Kerri and Schiefer, Sandy and Askins, Joe and Buchanan, Sarah A.},
  title = {Endangered but not too late: The state of digital news preservation},
  year = {2021},
  publisher = {Donald W. Reynolds Journalism Institute, University of Missouri--Columbia Libraries},
  url = {https://hdl.handle.net/10355/80931},
  doi = {10.32469/10355/80931},
  note = {OpenAccess. Licensed under CC BY 4.0}
}

@article{barney1991,
  author = {Barney, Jay},
  title = {Firm Resources and Sustained Competitive Advantage},
  journal = {Journal of Management},
  volume = {17},
  number = {1},
  pages = {99-120},
  year = {1991},
  publisher = {SAGE},
  doi = {10.1177/014920639101700108}
}


@article{Civelek2023,
  author    = {Mehmet Civelek and Vladim{\'i}r Kraj{\v{c}}{\'i}k and Aleksandr Klju{\v{c}}nikov},
  title     = {The impacts of dynamic capabilities on SMEs' digital transformation process: The resource-based view perspective},
  journal   = {Oeconomia Copernicana},
  volume    = {14},
  number    = {4},
  pages     = {1367--1392},
  year      = {2023},
  doi       = {10.24136/oc.2023.019},
  url       = {https://doi.org/10.24136/oc.2023.019},
  keywords  = {digital transformation, digital literacy, cyber-security, dynamic capabilities, Resource-Based View, SMEs},
  publisher = {Institute of Economic Research, Poland}
}

@article{LOVE2019102930,
title = {The ‘how’ of benefits management for digital technology: From engineering to asset management},
journal = {Automation in Construction},
volume = {107},
pages = {102930},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.102930},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519304297},
author = {Peter E.D. Love and Jane Matthews},
}

@article{Haneltarticle,
author = {Hanelt, André and Bohnsack, René and Marz, David and Antunes Marante, Claudia},
year = {2020},
month = {10},
pages = {},
title = {A Systematic Review of the Literature on Digital Transformation: Insights and Implications for Strategy and Organizational Change},
journal = {Journal of Management Studies},
doi = {10.1111/joms.12639}
}


@misc{UN2030Agenda,
  title        = {Transforming Our World: The 2030 Agenda for Sustainable Development},
  author       = {{United Nations}},
  year         = {2015},
  url          = {https://sdgs.un.org/2030agenda},
  note         = {Accessed: February 28, 2025}
}

@article{jobin2019global,
  author    = {Jobin, Anna and Ienca, Marcello and Vayena, Effy},
  title     = {The Global Landscape of AI Ethics Guidelines},
  journal   = {Nature Machine Intelligence},
  volume    = {1},
  pages     = {389--399},
  year      = {2019},
  publisher = {Springer Nature},
  doi       = {10.1038/s42256-019-0088-2}
}


@article{hevner2004design,
  author    = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
  title     = {Design Science in Information Systems Research},
  journal   = {MIS Quarterly},
  volume    = {28},
  number    = {1},
  pages     = {75--105},
  year      = {2004},
  publisher = {Association for Information Systems},
  doi       = {10.2307/20168918}
}

@book{simon1996sciences,
  title={The Sciences of the Artificial},
  author={Simon, Herbert A},
  edition={3rd},
  year={1996},
  publisher={MIT Press},
  address={Cambridge, MA}
}

@incollection{vomBrocke2020introduction,
  author       = {Jan vom Brocke and Alan Hevner and Alexander Maedche},
  title        = {Introduction to Design Science Research},
  booktitle    = {Design Science Research: Cases},
  editor       = {Jan vom Brocke and Alan Hevner and Alexander Maedche},
  publisher    = {Springer, Cham},
  year         = {2020},
  pages        = {1--16},
  doi          = {10.1007/978-3-030-46781-4_1},
  url          = {https://doi.org/10.1007/978-3-030-46781-4_1}
}

@article{gregor2013positioning,
  title={Positioning and Presenting Design Science Research for Maximum Impact},
  author={Gregor, Shirley and Hevner, Alan R.},
  journal={MIS Quarterly},
  volume={37},
  number={2},
  pages={337--355},
  year={2013}
}
@misc{gdpr,
  author = {{European Union}},
  title  = {{Regulation (EU) 2016/679 of the European Parliament and of the Council on the protection of natural persons}},
  year   = {2016},
  howpublished = {\url{https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32016R0679}},
  note   = {Accessed: 2025-03-12}
}

@misc{etik,
  author = {{Swedish Parliament}},
  title  = {{Lag (2003:460) om etikprövning av forskning som avser människor}},
  year   = {2003},
  howpublished = {\url{https://www.riksdagen.se/sv/dokument-lagar/dokument/svensk-forfattningssamling/lag-2003460-om-etikprovning-av-forskning-som_sfs-2003-460}},
  note   = {Accessed: 2025-03-12}
}

@misc{roboflow_terms,
  author       = {{Roboflow Inc.}},
  title        = {Roboflow Terms of Service},
  year         = {2024},
  howpublished = {\url{https://roboflow.com/terms}},
  note         = {Accessed: 2025-04-12}
}

@misc{colab_terms,
  author       = {{Google Inc.}},
  title        = {Google Colab Terms of Service},
  year         = {2024},
  howpublished = {\url{https://colab.research.google.com/pro/terms/v1}},
  note         = {Accessed: 2025-04-12}
}


@article{crasto2024imbalance,
  title={Class Imbalance in Object Detection: An Experimental Diagnosis and Study of Mitigation Strategies},
  author={Crasto, Nieves},
  journal={arXiv preprint arXiv:2403.07113},
  year={2024},
  url={https://arxiv.org/abs/2403.07113}
}

@inproceedings{carion2020detr,
  title={End-to-End Object Detection with Transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={213--229},
  year={2020},
  publisher={Springer},
  doi={10.1007/978-3-030-58452-8_13}
}


@misc{yolov12repo,
  author       = {Jie, Sun},
  title        = {YOLOv12 - Ultralytics-style object detector},
  year         = {2025},
  month        = feb,
  day          = {22},
  howpublished = {\url{https://github.com/sunsmarterjie/yolov12}},
  note         = {Accessed: 2025-04-13}
}





@book{creswell2014,
  title     = {Research Design: Qualitative, Quantitative, and Mixed Methods Approaches},
  author    = {Creswell, John W.},
  edition   = {4th},
  year      = {2014},
  publisher = {SAGE Publications}
}

@book{yin2014case,
  title     = {Case Study Research: Design and Methods},
  author    = {Yin, Robert K.},
  edition   = {5th},
  year      = {2014},
  publisher = {SAGE Publications}
}

@article{johnson2004mixed,
  title     = {Mixed Methods Research: A Research Paradigm Whose Time Has Come},
  author    = {Johnson, R. Burke and Onwuegbuzie, Anthony J.},
  journal   = {Educational Researcher},
  volume    = {33},
  number    = {7},
  pages     = {14--26},
  year      = {2004},
  publisher = {SAGE Publications}
}


@article{MINGfANG,
author = {Wu, Mingfang and Brandhorst, Hans and Marinescu, maria-cristina and Moré, Joaquim and Hlava, Marjorie and Busch, Joseph},
year = {2022},
month = {09},
pages = {1-17},
title = {Automated metadata annotation: What is and is not possible with machine learning},
volume = {5},
journal = {Data Intelligence},
doi = {10.1162/dint_a_00162}
}



@inproceedings{redmon2016you,
  title={You Only Look Once: Unified, Real-Time Object Detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={779--788},
  year={2016},
  url={http://pjreddie.com/yolo/}
}

@misc{redmon2016yolo9000betterfasterstronger,
      title={YOLO9000: Better, Faster, Stronger}, 
      author={Joseph Redmon and Ali Farhadi},
      year={2016},
      eprint={1612.08242},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1612.08242}, 
}

@misc{redmon2018yolov3,
  title={YOLOv3: An Incremental Improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  year={2018},
  eprint={1804.02767},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  note={arXiv:1804.02767v1}
}

@misc{bochkovskiy2020yolov4,
  title={YOLOv4: Optimal Speed and Accuracy of Object Detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  year={2020},
  eprint={2004.10934},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  note={arXiv:2004.10934v1, 23 Apr 2020}
}

@misc{ultralytics2024yolov5,
  title = {Comprehensive Guide to Ultralytics YOLOv5},
  author = {Ultralytics},
  year = {2020},
  url = {https://docs.ultralytics.com/yolov5/},
  note = {Accessed: 21 February 2025}
}

@article{wang2022yolov7,
  title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2207.02696},
  year={2022},
  month={Jul},
  note={Version 1, 6 Jul 2022}
}

@misc{li2022yolov6,
  title={YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications},
  author={Chuyi Li and Lulu Li and Hongliang Jiang and Kaiheng Weng and Yifei Geng and Liang Li and Zaidan Ke and Qingyuan Li and Meng Cheng and Weiqiang Nie and Yiduo Li and Bo Zhang and Yufei Liang and Linyuan Zhou and Xiaoming Xu and Xiangxiang Chu and Xiaoming Wei and Xiaolin Wei},
  year={2022},
  eprint={2209.02976},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/pdf/2209.02976}
}

@misc{ultralytics2025yolov8,
  title={YOLOv8: A Unified Architecture for Object Detection, Classification, and Segmentation},
  author={Ultralytics},
  year={2023},
  howpublished={\url{https://yolov8.com/}},
  note={Accessed: 2025-03-01}
}

@inproceedings{zhu2021deformabledetr,
  title={Deformable DETR: Deformable Transformers for End-to-End Object Detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021},
  url={https://arxiv.org/abs/2010.04159}
}
@misc{wang2024yolov10,
      title={YOLOv10: Real-Time End-to-End Object Detection}, 
      author={Ao Wang and Hui Chen and Lihao Liu and Kai Chen and Zijia Lin and Jungong Han and Guiguang Ding},
      year={2024},
      eprint={2405.14458},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.14458}, 
}

@article{wang2024yolov9,
  title={YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information},
  author={Wang, Chien-Yao and Yeh, I-Hau and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2402.13616},
  year={2024}
}

@misc{UltralyticsYOLO11,
  title        = "{Ultralytics YOLO11}",
  author       = "{Ultralytics Inc.}",
  howpublished = "\url{https://docs.ultralytics.com/models/yolo11/}",
  year         = "2025",
  note         = "Accessed: 3 March 2025"
}


@misc{khanam2024yolov11overviewkeyarchitectural,
      title={YOLOv11: An Overview of the Key Architectural Enhancements}, 
      author={Rahima Khanam and Muhammad Hussain},
      year={2024},
      eprint={2410.17725},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.17725}, 
}


@misc{hidayatullah2025yolov8yolo11comprehensivearchitecture,
      title={YOLOv8 to YOLO11: A Comprehensive Architecture In-depth Comparative Review}, 
      author={Priyanto Hidayatullah and Nurjannah Syakrani and Muhammad Rizqi Sholahuddin and Trisna Gelar and Refdinal Tubagus},
      year={2025},
      eprint={2501.13400},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.13400}, 
}


@ARTICLE{10589380,
  author={Khanam, Rahima and Hussain, Muhammad and Hill, Richard and Allen, Paul},
  journal={IEEE Access}, 
  title={A Comprehensive Review of Convolutional Neural Networks for Defect Detection in Industrial Applications}, 
  year={2024},
  volume={12},
  number={},
  pages={94250-94295},
  keywords={Defect detection;Hardware;Convolutional neural networks;Computer architecture;Reviews;Artificial intelligence;Inspection;Computer vision;Deep learning;Quality assessment;Manufacturing processes;Computer vision;convolutional neural network;deep learning;industrial defect detection;object detection;quality inspection: manufacturing},
  doi={10.1109/ACCESS.2024.3425166}}



@article{SOORI202354,
title = {Artificial intelligence, machine learning and deep learning in advanced robotics, a review},
journal = {Cognitive Robotics},
volume = {3},
pages = {54-70},
year = {2023},
issn = {2667-2413},
doi = {https://doi.org/10.1016/j.cogr.2023.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2667241323000113},
author = {Mohsen Soori and Behrooz Arezoo and Roza Dastres},}}

@book{Goodfellow-et-al-2016,
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  title     = {Deep Learning},
  publisher = {MIT Press},
  year      = {2016},
  url       = {https://www.deeplearningbook.org/},
  chapter   = {9},
  pages     = {326},
}



@article{ZhangLei2025RoMH,
author = {Zhang, Lei and Sun, Zhipeng and Tao, Hongjing and Wang, Meng and Yi, Weixun},
address = {Switzerland},
copyright = {COPYRIGHT 2025 MDPI AG},
issn = {1424-8220},
journal = {Sensors (Basel, Switzerland)},
keywords = {Algorithms ; Coal mines and mining ; Efficiency ; Helmets ; Industrial hygiene ; Industrial safety ; Methodology ; Methods ; Mines and mineral resources ; Safety regulations},
language = {eng},
number = {1},
pages = {170-},
publisher = {MDPI AG},
title = {Research on Mine-Personnel Helmet Detection Based on Multi-Strategy-Improved YOLOv11},
volume = {25},
year = {2025},
}


@article{KARBOUJ2024527,
  author = {Bsher Karbouj and Garabet A. Topalian-Rivas and Jörg Krüger},
  title = {Comparative Performance Evaluation of One-Stage and Two-Stage Object Detectors for Screw Head Detection and Classification in Disassembly Processes},
  journal = {Procedia CIRP},
  volume = {122},
  pages = {527-532},
  year = {2024},
  note = {31st CIRP Conference on Life Cycle Engineering (LCE 2024)},
  issn = {2212-8271},
  doi = {10.1016/j.procir.2024.01.077},
  url = {https://www.sciencedirect.com/science/article/pii/S2212827124001021},
  publisher = {Elsevier},
}

@article{Sapkota2025YOLOv11,
  author = {Ranjan Sapkota and Rizwan Qureshi and Marco Flores-Calero and Chetan Badgujar and Upesh Nepal and Alwin Poulose and Peter Zeno and Uday Bhanu Prakash Vaddevolu and Sheheryar Khan and Maged Shoman and Hong Yan and Manoj Karkee},
  title = {YOLO11 to Its Genesis: A Decadal and Comprehensive Review of The You Only Look Once (YOLO) Series},
  journal = {arXiv},
  year = {2025},
  volume = {2406},
  number = {19407v5},
  month = {January},
  doi = {10.48550/arXiv.2406.19407},
  url = {https://arxiv.org/abs/2406.19407},
  eprint = {2406.19407},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
  abstract = {This review systematically examines the progression of the You Only Look Once (YOLO) object detection algorithms from YOLOv1 to the recently unveiled YOLO11 (or YOLOv11). Employing a reverse chronological analysis, this study examines the advancements introduced by YOLO algorithms, beginning with YOLOv11 and progressing through earlier versions to explore contributions to speed, detection accuracy, and computational efficiency in real-time object detection. The review chronicles the evolution of YOLO and discusses the challenges and limitations in earlier versions, signifying a path towards integrating YOLO with multimodal, context-aware, and Artificial General Intelligence (AGI) systems for the next decade.},
  keywords = {YOLO, Real-time Object Detection, Deep Learning, CNN, Computer Vision, Artificial Intelligence, Autonomous Vehicles, Surveillance, Industrial Manufacturing, Healthcare, Medical Imaging, Traffic Safety, Agriculture},
  publisher = {Cornell University},
  institution = {Biological & Environmental Engineering, Cornell University}
}


@inbook{Angulo_2019,
   title={Road Damage Detection Acquisition System Based on Deep Neural Networks for Physical Asset Management},
   ISBN={9783030337490},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-030-33749-0_1},
   DOI={10.1007/978-3-030-33749-0_1},
   booktitle={Advances in Soft Computing},
   publisher={Springer International Publishing},
   author={Angulo, Andres and Vega-Fernández, Juan Antonio and Aguilar-Lobo, Lina Maria and Natraj, Shailendra and Ochoa-Ruiz, Gilberto},
   year={2019},
   pages={3–14} }


@misc{he2024comprehensiveperformanceevaluationyolov11,
      title={Comprehensive Performance Evaluation of YOLOv11, YOLOv10, YOLOv9, YOLOv8 and YOLOv5 on Object Detection of Power Equipment}, 
      author={Zijian He and Kang Wang and Tian Fang and Lei Su and Rui Chen and Xihong Fei},
      year={2024},
      eprint={2411.18871},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.18871}, 
}

@article{articleRANE,
author = {Rane, Nitin},
year = {2023},
month = {01},
pages = {},
title = {YOLO and Faster R-CNN object detection for smart Industry 4.0 and Industry 5.0: applications, challenges, and opportunities},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.4624206}
}

@article{vina2024yolo11,
  author = {Abirami Vina},
  title = {The Benefits of Ultralytics YOLO11 Being an Anchor-Free Detector},
  year = {2024},
  month = {December},
  journal = {Ultralytics Blog},
  url = {https://www.ultralytics.com/blog/benefits-ultralytics-yolo11-being-anchor-free-detector}
}

@article{alif2025yolov12,
  author    = {Mujadded Al Rabbani Alif and Muhammad Hussain},
  title     = {YOLOv12: A Breakdown of the Key Architectural Features},
  journal   = {arXiv preprint},
  volume    = {arXiv:2502.14740v1},
  year      = {2025},
  month     = {February},
  day       = {20},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
  institution = {Department of Computer Science, Huddersfield University, Queensgate, Huddersfield HD1 3DH, UK},
  note      = {arXiv.org perpetual non-exclusive license},
  url       = {https://arxiv.org/abs/2502.14740v1}
}


@book{VerdhanVaibhav2021CVUD,
abstract = {Organizations spend huge resources in developing software that can perform the way a human does. Image classification, object detection and tracking, pose estimation, facial recognition, and sentiment estimation all play a major role in solving computer vision problems.
This book will bring into focus these and other deep learning architectures and techniques to help you create solutions using Keras and the TensorFlow library. You'll also review mutliple neural network architectures, including LeNet, AlexNet, VGG, Inception, R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN, YOLO, and SqueezeNet and see how they work alongside Python code via best practices, tips, tricks, shortcuts, and pitfalls.All code snippets will be broken down and discussed thoroughly so you can implement the same principles in your respective environments.
Computer Vision Using Deep Learning offers a comprehensive yet succinct guide that stitches DL and CV together to automate operations, reduce human intervention, increase capability, and cut the costs.
What You'll Learn
* Examine deep learning code and concepts to apply guiding principals to your own projects
* Classify and evaluate various architectures to better understand your options in various use cases
* Go behind the scenes of basic deep learning functions to find out how they work
Who This Book Is For
Professional practitioners working in the fields of software engineering and data science. A working knowledge of Python is strongly recommended. Students and innovators working on advanced degrees in areas related to computer vision and Deep Learning.},
author = {Verdhan, Vaibhav},
address = {Berkeley, CA},
copyright = {Vaibhav Verdhan 2021. Apress standard},
edition = {1st ed.},
isbn = {1484266161},
keywords = {Artificial intelligence ; Computer games ; Computer programming ; Computer science ; Computer vision ; Computers ; Programming ; Python (Computer program language) ; Video games},
language = {eng},
publisher = {Apress},
title = {Computer Vision Using Deep Learning: Neural Network Architectures with Python and Keras},
year = {2021},
}


@article{10589380TEST,
  author={Khanam, Rahima and Hussain, Muhammad and Hill, Richard and Allen, Paul},
  journal={IEEE Access}, 
  title={A Comprehensive Review of Convolutional Neural Networks for Defect Detection in Industrial Applications}, 
  year={2024},
  volume={12},
  number={},
  pages={94250-94295},
  keywords={Defect detection;Hardware;Convolutional neural networks;Computer architecture;Reviews;Artificial intelligence;Inspection;Computer vision;Deep learning;Quality assessment;Manufacturing processes;Computer vision;convolutional neural network;deep learning;industrial defect detection;object detection;quality inspection: manufacturing},
  doi={10.1109/ACCESS.2024.3425166}
}

@book{prince2023understanding,
        author = "Simon J.D. Prince",
        title = "Understanding Deep Learning",
        publisher = "The MIT Press",
        year = 2023,
        url = "http://udlbook.com"
    }
  

@misc{ultralytics2025,
  author       = {Glenn Jocher and Ultralytics},
  title        = {Ultralytics YOLOv11},
  year         = {2025},
  howpublished = {\url{https://github.com/ultralytics/ultralytics}},
  note         = {Accessed March 2025}
}



